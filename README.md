# Transformers-Pipelines
Practicing different pipelines and transformers

ğŸ§  **Transformers-Pipelines**
This repository contains hands-on experiments and demonstrations using Hugging Face Transformers pipelines, along with a comparison of manual sentiment analysis using TensorFlow. The goal is to understand the power of pre-built transformer pipelines versus building models from scratch.

ğŸ“‚ **Project Structure**

.
â”œâ”€â”€ README.md
â”œâ”€â”€ SentimentalAnalysis.ipynb
â””â”€â”€ Transformer_&_Pipeline.ipynb

ğŸ” **SentimentalAnalysis.ipynb**
Built a custom sentiment analysis model using TensorFlow and basic NLP preprocessing techniques.

No use of pipeline abstractions â€” a deep dive into model-building from the ground up.

ğŸ¤– **Transformer_&_Pipeline.ipynb**
Explored multiple Hugging Face Transformers pipelines such as:

Sentiment Analysis

Question Answering

Text Summarization

Named Entity Recognition

Demonstrated how to load models and tokenize input for various NLP tasks.

ğŸ“Œ **Key Concepts Practiced**
Tokenization

Transformers Pipelines

Pretrained Models

NLP Tasks using Hugging Face

Custom TensorFlow-based Sentiment Analysis

Input Preprocessing and Output Interpretation

ğŸ› ï¸ **Tools & Libraries Used**
Python

TensorFlow

Hugging Face Transformers

Numpy, Pandas

Google Colab

âœ… **Getting Started**
Clone the repository:

bash

git clone https://github.com/your-username/transformers-pipelines.git
cd transformers-pipelines

Open notebooks in Google Colab or Jupyter and run the cells step-by-step.
