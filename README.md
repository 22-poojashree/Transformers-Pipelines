# Transformers-Pipelines
Practicing different pipelines and transformers

🧠 **Transformers-Pipelines**
This repository contains hands-on experiments and demonstrations using Hugging Face Transformers pipelines, along with a comparison of manual sentiment analysis using TensorFlow. The goal is to understand the power of pre-built transformer pipelines versus building models from scratch.

📂 **Project Structure**

.
├── README.md
├── SentimentalAnalysis.ipynb
└── Transformer_&_Pipeline.ipynb

🔍 **SentimentalAnalysis.ipynb**
Built a custom sentiment analysis model using TensorFlow and basic NLP preprocessing techniques.

No use of pipeline abstractions — a deep dive into model-building from the ground up.

🤖 **Transformer_&_Pipeline.ipynb**
Explored multiple Hugging Face Transformers pipelines such as:

Sentiment Analysis

Question Answering

Text Summarization

Named Entity Recognition

Demonstrated how to load models and tokenize input for various NLP tasks.

📌 **Key Concepts Practiced**
Tokenization

Transformers Pipelines

Pretrained Models

NLP Tasks using Hugging Face

Custom TensorFlow-based Sentiment Analysis

Input Preprocessing and Output Interpretation

🛠️ **Tools & Libraries Used**
Python

TensorFlow

Hugging Face Transformers

Numpy, Pandas

Google Colab

✅ **Getting Started**
Clone the repository:

bash

git clone https://github.com/your-username/transformers-pipelines.git
cd transformers-pipelines

Open notebooks in Google Colab or Jupyter and run the cells step-by-step.
